{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from classifier import Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>randNumCol</th>\n",
       "      <th>HW0-old</th>\n",
       "      <th>HW0-old - Max Points</th>\n",
       "      <th>HW0-old - Submission Time</th>\n",
       "      <th>HW0-old - Lateness (H:M:S)</th>\n",
       "      <th>HW1</th>\n",
       "      <th>HW1 - Max Points</th>\n",
       "      <th>HW1 - Submission Time</th>\n",
       "      <th>HW1 - Lateness (H:M:S)</th>\n",
       "      <th>HW2</th>\n",
       "      <th>...</th>\n",
       "      <th>Project_FA22_code - Lateness (H:M:S)</th>\n",
       "      <th>Project_Fa22_ExtraCredits</th>\n",
       "      <th>Project_Fa22_ExtraCredits - Max Points</th>\n",
       "      <th>Project_Fa22_ExtraCredits - Submission Time</th>\n",
       "      <th>Project_Fa22_ExtraCredits - Lateness (H:M:S)</th>\n",
       "      <th>HW0</th>\n",
       "      <th>HW0 - Max Points</th>\n",
       "      <th>HW0 - Submission Time</th>\n",
       "      <th>HW0 - Lateness (H:M:S)</th>\n",
       "      <th>Total Lateness (H:M:S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801925577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2022-09-06 08:43:22 -0700</td>\n",
       "      <td>106:44:22</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:01:22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-12-10 20:58:06 -0800</td>\n",
       "      <td>190:59:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>297:45:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262507520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-08-23 09:49:04 -0700</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2022-09-01 21:58:56 -0700</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-08-24 14:46:39 -0700</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>853470508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2022-09-01 20:34:25 -0700</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-12-02 19:31:27 -0800</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-08-24 14:49:28 -0700</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>11:14:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>468287725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2022-09-01 21:46:46 -0700</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-12-02 21:56:30 -0800</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-08-30 20:43:07 -0700</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>01:12:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>966245481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>52.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2022-09-01 19:21:49 -0700</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>46.5</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   randNumCol  HW0-old  HW0-old - Max Points  HW0-old - Submission Time  \\\n",
       "0   801925577      NaN                   0.0                        NaN   \n",
       "1   262507520      NaN                   0.0  2022-08-23 09:49:04 -0700   \n",
       "2   853470508      NaN                   0.0                        NaN   \n",
       "3   468287725      NaN                   0.0                        NaN   \n",
       "4   966245481      NaN                   0.0                        NaN   \n",
       "\n",
       "  HW0-old - Lateness (H:M:S)   HW1  HW1 - Max Points  \\\n",
       "0                   00:00:00  48.0              55.0   \n",
       "1                   00:00:00  40.0              55.0   \n",
       "2                   00:00:00  43.0              55.0   \n",
       "3                   00:00:00  45.0              55.0   \n",
       "4                   00:00:00  52.5              55.0   \n",
       "\n",
       "       HW1 - Submission Time HW1 - Lateness (H:M:S)   HW2  ...  \\\n",
       "0  2022-09-06 08:43:22 -0700              106:44:22  48.0  ...   \n",
       "1  2022-09-01 21:58:56 -0700               00:00:00  44.0  ...   \n",
       "2  2022-09-01 20:34:25 -0700               00:00:00  49.0  ...   \n",
       "3  2022-09-01 21:46:46 -0700               00:00:00  51.0  ...   \n",
       "4  2022-09-01 19:21:49 -0700               00:00:00  46.5  ...   \n",
       "\n",
       "   Project_FA22_code - Lateness (H:M:S) Project_Fa22_ExtraCredits  \\\n",
       "0                              00:01:22                       4.0   \n",
       "1                              00:00:00                       NaN   \n",
       "2                              00:00:00                      15.0   \n",
       "3                              00:00:00                       4.0   \n",
       "4                              00:00:00                       NaN   \n",
       "\n",
       "  Project_Fa22_ExtraCredits - Max Points  \\\n",
       "0                                   15.0   \n",
       "1                                   15.0   \n",
       "2                                   15.0   \n",
       "3                                   15.0   \n",
       "4                                   15.0   \n",
       "\n",
       "   Project_Fa22_ExtraCredits - Submission Time  \\\n",
       "0                    2022-12-10 20:58:06 -0800   \n",
       "1                                          NaN   \n",
       "2                    2022-12-02 19:31:27 -0800   \n",
       "3                    2022-12-02 21:56:30 -0800   \n",
       "4                                          NaN   \n",
       "\n",
       "   Project_Fa22_ExtraCredits - Lateness (H:M:S) HW0 HW0 - Max Points  \\\n",
       "0                                     190:59:06 NaN              0.0   \n",
       "1                                      00:00:00 NaN              0.0   \n",
       "2                                      00:00:00 NaN              0.0   \n",
       "3                                      00:00:00 NaN              0.0   \n",
       "4                                      00:00:00 NaN              0.0   \n",
       "\n",
       "       HW0 - Submission Time  HW0 - Lateness (H:M:S) Total Lateness (H:M:S)  \n",
       "0                        NaN                00:00:00              297:45:05  \n",
       "1  2022-08-24 14:46:39 -0700                00:00:00               00:00:00  \n",
       "2  2022-08-24 14:49:28 -0700                00:00:00               11:14:30  \n",
       "3  2022-08-30 20:43:07 -0700                00:00:00               01:12:59  \n",
       "4                        NaN                00:00:00               00:00:00  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../grade_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grade(Dataset):    \n",
    "    def __init__(self, csv_file, max_length, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the CSV file.\n",
    "            src_lang (string): Source language.\n",
    "            tgt_lang (string): Target language.\n",
    "            tokenizer (callable): Tokenizer function.\n",
    "            max_length (int, optional): Maximum sequence length.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)  \n",
    "        self.max_length = max_length\n",
    "        self.transform = transform\n",
    "        self.HW = [] \n",
    "        for i in range(1, 11):\n",
    "            self.HW.append(f\"HW{i}\")\n",
    "        self.data = self.df.loc[:, self.HW]\n",
    "        self.data.dropna(axis=0, inplace=True)\n",
    "        self.train = self.data.iloc[:80]\n",
    "        self.eval = self.data.iloc[80:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        rows = self.train.iloc[idx]\n",
    "        input = rows[self.HW[:-1]].values\n",
    "        input = np.insert(input, 0, 56)\n",
    "        target = rows[self.HW[-1]]  \n",
    "        return input, target\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      HW1   HW2   HW3   HW4   HW5   HW6   HW7   HW8   HW9  HW10\n",
      "0    48.0  48.0  41.0  42.5  48.0  44.0  42.0  50.0  51.0  55.0\n",
      "2    43.0  49.0  45.0  50.0  50.0  50.0  49.0  49.0  48.0  50.0\n",
      "3    45.0  51.0  38.5  44.5  51.0  29.0  46.0  51.0  48.0  47.0\n",
      "6    42.0  51.0  44.5  52.0  45.0  50.0  48.0  46.0  51.0  52.0\n",
      "8    46.0  49.0  51.5  52.0  52.0  50.0  50.0  46.0  50.0  50.0\n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
      "344  46.0  47.5  47.0  46.5  50.0  48.5  50.0  44.0  52.0  55.0\n",
      "346  45.0  51.0  46.0  49.0  51.0  41.0  30.0  40.0  48.0  47.0\n",
      "350  42.5  50.0  46.0  52.0  52.0  52.0  50.0  51.0  50.0  55.0\n",
      "353  53.0  47.0  50.0  52.0  51.0  52.0  50.0  52.0  49.0  44.0\n",
      "355  45.0  49.0  47.5  42.0  38.0  50.0  50.0  49.0  50.0  50.0\n",
      "\n",
      "[95 rows x 10 columns]\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = \"../grade_data.csv\"\n",
    "max_seq_length = 16\n",
    "\n",
    "dataset = Grade(csv_file_path, max_length=max_seq_length)\n",
    "print(dataset.data)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56.  48.  48.  41.  42.5 48.  44.  42.  50.  51. ] 55.0\n"
     ]
    }
   ],
   "source": [
    "input, target = dataset[0]\n",
    "print(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the data loader\n",
    "batch_size = 16\n",
    "shuffle = True  \n",
    "\n",
    "# Create a data loader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "classifier = Classifier(num_layers=6, d_model=512, num_heads=8, d_ffn=256, input_vocab_size=60, output_vocab_size=60, max_seq_length=max_seq_length)\n",
    "optim = torch.optim.Adam(classifier.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "tensor(4.6176, grad_fn=<DivBackward1>)\n",
      "tensor(3.2284, grad_fn=<DivBackward1>)\n",
      "tensor(3.4755, grad_fn=<DivBackward1>)\n",
      "tensor(2.2093, grad_fn=<DivBackward1>)\n",
      "tensor(2.2592, grad_fn=<DivBackward1>)\n",
      "Epoch:  1\n",
      "tensor(2.5384, grad_fn=<DivBackward1>)\n",
      "tensor(1.6346, grad_fn=<DivBackward1>)\n",
      "tensor(2.2205, grad_fn=<DivBackward1>)\n",
      "tensor(1.9678, grad_fn=<DivBackward1>)\n",
      "tensor(2.0560, grad_fn=<DivBackward1>)\n",
      "Epoch:  2\n",
      "tensor(1.8244, grad_fn=<DivBackward1>)\n",
      "tensor(1.6600, grad_fn=<DivBackward1>)\n",
      "tensor(2.5234, grad_fn=<DivBackward1>)\n",
      "tensor(1.6779, grad_fn=<DivBackward1>)\n",
      "tensor(1.9186, grad_fn=<DivBackward1>)\n",
      "Epoch:  3\n",
      "tensor(1.0514, grad_fn=<DivBackward1>)\n",
      "tensor(1.8349, grad_fn=<DivBackward1>)\n",
      "tensor(1.9747, grad_fn=<DivBackward1>)\n",
      "tensor(1.9815, grad_fn=<DivBackward1>)\n",
      "tensor(2.1798, grad_fn=<DivBackward1>)\n",
      "Epoch:  4\n",
      "tensor(1.6886, grad_fn=<DivBackward1>)\n",
      "tensor(1.9341, grad_fn=<DivBackward1>)\n",
      "tensor(2.0196, grad_fn=<DivBackward1>)\n",
      "tensor(1.4448, grad_fn=<DivBackward1>)\n",
      "tensor(1.5004, grad_fn=<DivBackward1>)\n",
      "Epoch:  5\n",
      "tensor(2.1226, grad_fn=<DivBackward1>)\n",
      "tensor(1.4897, grad_fn=<DivBackward1>)\n",
      "tensor(1.8550, grad_fn=<DivBackward1>)\n",
      "tensor(1.1599, grad_fn=<DivBackward1>)\n",
      "tensor(1.6097, grad_fn=<DivBackward1>)\n",
      "Epoch:  6\n",
      "tensor(1.3080, grad_fn=<DivBackward1>)\n",
      "tensor(1.6705, grad_fn=<DivBackward1>)\n",
      "tensor(2.1439, grad_fn=<DivBackward1>)\n",
      "tensor(1.2986, grad_fn=<DivBackward1>)\n",
      "tensor(1.3059, grad_fn=<DivBackward1>)\n",
      "Epoch:  7\n",
      "tensor(1.6856, grad_fn=<DivBackward1>)\n",
      "tensor(1.3409, grad_fn=<DivBackward1>)\n",
      "tensor(1.1187, grad_fn=<DivBackward1>)\n",
      "tensor(1.8654, grad_fn=<DivBackward1>)\n",
      "tensor(1.1803, grad_fn=<DivBackward1>)\n",
      "Epoch:  8\n",
      "tensor(1.6335, grad_fn=<DivBackward1>)\n",
      "tensor(1.0924, grad_fn=<DivBackward1>)\n",
      "tensor(1.3962, grad_fn=<DivBackward1>)\n",
      "tensor(1.3750, grad_fn=<DivBackward1>)\n",
      "tensor(1.2586, grad_fn=<DivBackward1>)\n",
      "Epoch:  9\n",
      "tensor(1.4981, grad_fn=<DivBackward1>)\n",
      "tensor(1.4785, grad_fn=<DivBackward1>)\n",
      "tensor(0.8879, grad_fn=<DivBackward1>)\n",
      "tensor(0.9193, grad_fn=<DivBackward1>)\n",
      "tensor(1.1621, grad_fn=<DivBackward1>)\n",
      "Epoch:  10\n",
      "tensor(1.2803, grad_fn=<DivBackward1>)\n",
      "tensor(0.7497, grad_fn=<DivBackward1>)\n",
      "tensor(1.2561, grad_fn=<DivBackward1>)\n",
      "tensor(0.8228, grad_fn=<DivBackward1>)\n",
      "tensor(1.0321, grad_fn=<DivBackward1>)\n",
      "Epoch:  11\n",
      "tensor(0.8783, grad_fn=<DivBackward1>)\n",
      "tensor(0.6805, grad_fn=<DivBackward1>)\n",
      "tensor(0.8881, grad_fn=<DivBackward1>)\n",
      "tensor(0.6453, grad_fn=<DivBackward1>)\n",
      "tensor(1.1582, grad_fn=<DivBackward1>)\n",
      "Epoch:  12\n",
      "tensor(0.6474, grad_fn=<DivBackward1>)\n",
      "tensor(0.9006, grad_fn=<DivBackward1>)\n",
      "tensor(0.6407, grad_fn=<DivBackward1>)\n",
      "tensor(0.6835, grad_fn=<DivBackward1>)\n",
      "tensor(0.8015, grad_fn=<DivBackward1>)\n",
      "Epoch:  13\n",
      "tensor(0.5582, grad_fn=<DivBackward1>)\n",
      "tensor(0.6141, grad_fn=<DivBackward1>)\n",
      "tensor(0.7455, grad_fn=<DivBackward1>)\n",
      "tensor(0.7352, grad_fn=<DivBackward1>)\n",
      "tensor(0.5458, grad_fn=<DivBackward1>)\n",
      "Epoch:  14\n",
      "tensor(0.5104, grad_fn=<DivBackward1>)\n",
      "tensor(0.6094, grad_fn=<DivBackward1>)\n",
      "tensor(0.4528, grad_fn=<DivBackward1>)\n",
      "tensor(0.6244, grad_fn=<DivBackward1>)\n",
      "tensor(0.3092, grad_fn=<DivBackward1>)\n",
      "Epoch:  15\n",
      "tensor(0.4402, grad_fn=<DivBackward1>)\n",
      "tensor(0.4320, grad_fn=<DivBackward1>)\n",
      "tensor(0.5085, grad_fn=<DivBackward1>)\n",
      "tensor(0.3430, grad_fn=<DivBackward1>)\n",
      "tensor(0.3748, grad_fn=<DivBackward1>)\n",
      "Epoch:  16\n",
      "tensor(0.3202, grad_fn=<DivBackward1>)\n",
      "tensor(0.5698, grad_fn=<DivBackward1>)\n",
      "tensor(0.3375, grad_fn=<DivBackward1>)\n",
      "tensor(0.3622, grad_fn=<DivBackward1>)\n",
      "tensor(0.2670, grad_fn=<DivBackward1>)\n",
      "Epoch:  17\n",
      "tensor(0.2891, grad_fn=<DivBackward1>)\n",
      "tensor(0.3338, grad_fn=<DivBackward1>)\n",
      "tensor(0.2973, grad_fn=<DivBackward1>)\n",
      "tensor(0.2354, grad_fn=<DivBackward1>)\n",
      "tensor(0.2395, grad_fn=<DivBackward1>)\n",
      "Epoch:  18\n",
      "tensor(0.1966, grad_fn=<DivBackward1>)\n",
      "tensor(0.3276, grad_fn=<DivBackward1>)\n",
      "tensor(0.2189, grad_fn=<DivBackward1>)\n",
      "tensor(0.2074, grad_fn=<DivBackward1>)\n",
      "tensor(0.1956, grad_fn=<DivBackward1>)\n",
      "Epoch:  19\n",
      "tensor(0.2056, grad_fn=<DivBackward1>)\n",
      "tensor(0.1842, grad_fn=<DivBackward1>)\n",
      "tensor(0.1680, grad_fn=<DivBackward1>)\n",
      "tensor(0.1067, grad_fn=<DivBackward1>)\n",
      "tensor(0.1697, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "classifier.train()\n",
    "epoch = 20\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"Epoch: \", i)\n",
    "    for input, target in dataloader:\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        input = input.to(torch.int64) \n",
    "        target = target.to(torch.int64) \n",
    "        \n",
    "        output = classifier(input)\n",
    "        output = output[:, 0, :].float()\n",
    "        \n",
    "        \n",
    "        target = F.one_hot(target, num_classes=60).float()\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        print(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'encoder_classifier.pth'\n",
    "\n",
    "# Save the model\n",
    "torch.save(classifier.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): WordEmbedding(\n",
       "      (embedding): Embedding(60, 512)\n",
       "    )\n",
       "    (pe): PositionalEncoding()\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (multihead_attention): MultiHeadAttention(\n",
       "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): FeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNormalization()\n",
       "        (layer_norm2): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_projection): Linear(in_features=512, out_features=60, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Classifier(num_layers=6, d_model=512, num_heads=8, d_ffn=256, input_vocab_size=60, output_vocab_size=60, max_seq_length=max_seq_length)\n",
    "classifier.load_state_dict(torch.load(\"./encoder_classifier.pth\"))\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56.  48.  48.  41.  42.5 48.  44.  42.  50.  51. ] 55.0\n",
      "torch.Size([1, 60])\n",
      "tensor(55)\n"
     ]
    }
   ],
   "source": [
    "input, target = dataset[0]\n",
    "print(input, target)\n",
    "\n",
    "input = torch.from_numpy(input).to(torch.int64).unsqueeze(0)\n",
    "output = classifier(input)\n",
    "output = output[:, 0, :].float()\n",
    "print(output.shape)\n",
    "softmax_output = F.softmax(output, dim=1)\n",
    "prediction = torch.argmax(softmax_output)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  55.0  Prediction:  tensor(55)\n",
      "Target:  55.0  Prediction:  tensor(50)\n",
      "Target:  52.0  Prediction:  tensor(45)\n",
      "Target:  50.0  Prediction:  tensor(55)\n",
      "Target:  55.0  Prediction:  tensor(55)\n",
      "Target:  50.0  Prediction:  tensor(50)\n",
      "Target:  55.0  Prediction:  tensor(40)\n",
      "Target:  50.0  Prediction:  tensor(50)\n",
      "Target:  50.0  Prediction:  tensor(55)\n",
      "Target:  55.0  Prediction:  tensor(35)\n",
      "Target:  55.0  Prediction:  tensor(30)\n",
      "Target:  47.0  Prediction:  tensor(55)\n",
      "Target:  55.0  Prediction:  tensor(52)\n",
      "Target:  44.0  Prediction:  tensor(55)\n",
      "Target:  50.0  Prediction:  tensor(50)\n",
      "Accuracy:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "eval = dataset.eval.values\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(dataset.eval)):\n",
    "    input = eval[i][:9]\n",
    "    target = eval[i][-1]\n",
    "    input = torch.from_numpy(input).to(torch.int64).unsqueeze(0)\n",
    "    output = classifier(input)\n",
    "    output = output[:, 0, :].float() \n",
    "    softmax_output = F.softmax(output, dim=1)\n",
    "    prediction = torch.argmax(softmax_output)\n",
    "    print(\"Target: \", target, \" Prediction: \", prediction)\n",
    "    if prediction == target:\n",
    "        correct += 1\n",
    "print(\"Accuracy: \", correct / len(eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
